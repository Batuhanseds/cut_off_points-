{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74912007",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import sqrt\n",
    "from numpy import argmax\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve,f1_score\n",
    "from matplotlib import pyplot\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c87818",
   "metadata": {},
   "outputs": [],
   "source": [
    "# roc curve for logistic regression model with optimal threshold\n",
    "from numpy import sqrt\n",
    "from numpy import argmax\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve\n",
    "from matplotlib import pyplot\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# generate dataset\n",
    "X, y = make_classification(n_samples=10000, n_features=2, n_redundant=0,n_clusters_per_class=1, weights=[0.99], flip_y=0, random_state=4)\n",
    "# split into train/test sets\n",
    "trainX, testX, trainy, testy = train_test_split(X, y, test_size=0.5, random_state=2, stratify=y)\n",
    "# fit a model\n",
    "model = LogisticRegression(solver='lbfgs')\n",
    "model.fit(trainX, trainy)\n",
    "# predict probabilities\n",
    "yhat = model.predict_proba(testX)\n",
    "# keep probabilities for the positive outcome only\n",
    "yhat = yhat[:, 1]\n",
    "# calculate roc curves\n",
    "fpr, tpr, thresholds = roc_curve(testy, yhat)\n",
    "# calculate the g-mean for each threshold\n",
    "gmeans = sqrt(tpr * (1-fpr))\n",
    "# locate the index of the largest g-mean\n",
    "ix = argmax(gmeans)\n",
    "print('Best Threshold=%f, G-Mean=%.3f' % (thresholds[ix], gmeans[ix]))\n",
    "# plot the roc curve for the model\n",
    "pyplot.plot([0,1], [0,1], linestyle='--', label='No Skill')\n",
    "pyplot.plot(fpr, tpr, marker='.', label='Logistic')\n",
    "pyplot.scatter(fpr[ix], tpr[ix], marker='o', color='black', label='Best')\n",
    "# axis labels\n",
    "pyplot.xlabel('False Positive Rate')\n",
    "pyplot.ylabel('True Positive Rate')\n",
    "pyplot.legend()\n",
    "# show the plot\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac632289",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "\n",
    "def visualize_3d(X,y,algorithm=\"tsne\",title=\"Data in 3D\"):\n",
    "    from sklearn.manifold import TSNE\n",
    "    from sklearn.decomposition import PCA\n",
    "    \n",
    "    if algorithm==\"tsne\":\n",
    "        reducer = TSNE(n_components=3,random_state=47,n_iter=400,angle=0.6)\n",
    "    elif algorithm==\"pca\":\n",
    "        reducer = PCA(n_components=3,random_state=47)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported dimensionality reduction algorithm given.\")\n",
    "    \n",
    "    if X.shape[1]>3:\n",
    "        X = reducer.fit_transform(X)\n",
    "    else:\n",
    "        if type(X)==pd.DataFrame:\n",
    "            X=X.values\n",
    "    \n",
    "    marker_shapes = [\"circle\",\"diamond\", \"circle-open\", \"square\",  \"diamond-open\", \"cross\",\"square-open\",]\n",
    "    traces = []\n",
    "    for hue in np.unique(y):\n",
    "        X1 = X[y==hue]\n",
    "\n",
    "        trace = go.Scatter3d(\n",
    "            x=X1[:,0],\n",
    "            y=X1[:,1],\n",
    "            z=X1[:,2],\n",
    "            mode='markers',\n",
    "            name = str(hue),\n",
    "            marker=dict(\n",
    "                size=5,\n",
    "                symbol=marker_shapes.pop(),\n",
    "                line=dict(\n",
    "                    width=int(np.random.randint(3,10)/10)\n",
    "                ),\n",
    "                opacity=int(np.random.randint(6,10)/10)\n",
    "            )\n",
    "        )\n",
    "        traces.append(trace)\n",
    "\n",
    "\n",
    "    layout = go.Layout(\n",
    "        title=title,\n",
    "        scene=dict(\n",
    "            xaxis=dict(\n",
    "                title='Dim 1'),\n",
    "            yaxis=dict(\n",
    "                title='Dim 2'),\n",
    "            zaxis=dict(\n",
    "                title='Dim 3'), ),\n",
    "        margin=dict(\n",
    "            l=0,\n",
    "            r=0,\n",
    "            b=0,\n",
    "            t=0\n",
    "        )\n",
    "    )\n",
    "    fig = go.Figure(data=traces, layout=layout)\n",
    "    iplot(fig)\n",
    "\n",
    "    \n",
    "def visualize_2d(X,y,algorithm=\"tsne\",title=\"Data in 2D\",figsize=(8,8)):\n",
    "    from sklearn.manifold import TSNE\n",
    "    from sklearn.decomposition import PCA\n",
    "    if algorithm==\"tsne\":\n",
    "        reducer = TSNE(n_components=2,random_state=47,n_iter=400,angle=0.6)\n",
    "    elif algorithm==\"pca\":\n",
    "        reducer = PCA(n_components=2,random_state=47)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported dimensionality reduction algorithm given.\")\n",
    "    if X.shape[1]>2:\n",
    "        X = reducer.fit_transform(X)\n",
    "    else:\n",
    "        if type(X)==pd.DataFrame:\n",
    "        \tX=X.values\n",
    "    f, (ax1) = plt.subplots(nrows=1, ncols=1,figsize=figsize)\n",
    "    sns.scatterplot(X[:,0],X[:,1],hue=y,ax=ax1);\n",
    "    ax1.set_title(title);\n",
    "    plt.show();\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90933d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All unique features\n",
    "X,y = make_classification(n_samples=7000, \n",
    "                          n_features=3, #feature that function gives\n",
    "                          n_informative=3, #feature that is relevent with classes\n",
    "                          n_redundant=0, #feature that is not relevent with classes\n",
    "                          n_repeated=0, #duplicated features\n",
    "                          n_classes=2, #how many cluster funciton gibes\n",
    "                          n_clusters_per_class=2, #how many classters will be in per calasses\n",
    "                          weights=[0.5,0.5], #How much point will be for each class\n",
    "                          flip_y=0.03, #Noise fore the classes, big value hard classification\n",
    "                          class_sep=0.1, #coralation between classes and the features, big value more coralation\n",
    "                          hypercube=True, #If true class are coralete hypercube else polytope\n",
    "                          scale=2,\n",
    "                          shuffle=True,\n",
    "                          random_state=77)\n",
    "visualize_3d(X,y,algorithm=\"pca\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59b674e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX, testX, trainy, testy = train_test_split(X, y, test_size=0.7, random_state=2, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb56155",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_curve\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "figure(figsize=(8, 6), dpi=150)\n",
    "\n",
    "def to_labels(pos_probs, threshold):\n",
    "    return (pos_probs >= threshold).astype('int')\n",
    " \n",
    "model = LogisticRegression(solver='lbfgs')\n",
    "model.fit(trainX, trainy)\n",
    "# predict probabilities\n",
    "yhat = model.predict_proba(testX)\n",
    "# keep probabilities for the positive outcome only\n",
    "yhat = yhat[:, 1]\n",
    "# calculate roc curves\n",
    "fpr, tpr, thresholds = roc_curve(testy, yhat)\n",
    "# calculate the g-mean for each threshold\n",
    "gmeans = sqrt(tpr * (1-fpr))\n",
    "# locate the index of the largest g-mean\n",
    "ix1 = argmax(gmeans)\n",
    "print('Best Threshold=%f, LogisticRegression G-Mean=%.3f' % (thresholds[ix], gmeans[ix]))\n",
    "# plot the roc curve for the model\n",
    "pyplot.plot([0,1], [0,1], linestyle='--', label='No Skill')\n",
    "pyplot.plot(fpr, tpr, marker='.', label='Logistic')\n",
    "pyplot.scatter(fpr[ix1], tpr[ix1], s=150, marker='o', color='black', label='Best Logistic G-Mean')\n",
    " \n",
    "model = XGBClassifier()\n",
    "model.fit(trainX, trainy)\n",
    "# predict probabilities\n",
    "yhat = model.predict_proba(testX)\n",
    "# keep probabilities for the positive outcome only\n",
    "yhat = yhat[:, 1]\n",
    "# calculate roc curves\n",
    "fpr, tpr, thresholds = roc_curve(testy, yhat)\n",
    "# calculate the g-mean for each threshold\n",
    "gmeans = sqrt(tpr * (1-fpr))\n",
    "# locate the index of the largest g-mean\n",
    "ix2 = argmax(gmeans)\n",
    "print('Best Threshold=%f, XGBClassifier G-Mean=%.3f' % (thresholds[ix2], gmeans[ix2]))\n",
    "print(pd.DataFrame(confusion_matrix(testy, to_labels(yhat, thresholds[ix2]))))\n",
    "print(classification_report(testy, to_labels(yhat, thresholds[ix2])))\n",
    "\n",
    "#Calculate succes with F1\n",
    "f1_list = [f1_score(testy, to_labels(yhat, t)) for t in thresholds]\n",
    "ix3 = argmax(f1_list)\n",
    "print('Max F1 ',f1_list[ix3])\n",
    "\n",
    "#Calculate succes with confusion matrix 1\n",
    "tnv, fpv, fnv, tpv =   1,  1,  1,  1\n",
    "cm_list=[]\n",
    "cm_list = [confusion_matrix(testy, to_labels(yhat, t)).ravel() for t in thresholds]\n",
    "values=[((t[0]*tnv)-(t[1]*fpv)-(t[2]*fnv)+(t[3]*tpv)) for t in cm_list]\n",
    "ix4=argmax(values)\n",
    "\n",
    "#Calculate succes with confusion matrix 2\n",
    "tnv, fpv, fnv, tpv =   1,  2,  5,  3\n",
    "values=[((t[0]*tnv)-(t[1]*fpv)-(t[2]*fnv)+(t[3]*tpv)) for t in cm_list]\n",
    "ix5=argmax(values)\n",
    "\n",
    "#Calculate succes with confusion matrix 3\n",
    "tnv, fpv, fnv, tpv =   4,  2,  2,  3\n",
    "values=[((t[0]*tnv)-(t[1]*fpv)-(t[2]*fnv)+(t[3]*tpv)) for t in cm_list]\n",
    "ix6=argmax(values)\n",
    "\n",
    "\n",
    "print('Threshold=%.3f, XGBClassifier Values=%.5f' % (thresholds[ix3],values[ix3]))\n",
    "print(pd.DataFrame(confusion_matrix(testy, to_labels(yhat, thresholds[ix3]))))\n",
    "print(classification_report(testy, to_labels(yhat, thresholds[ix3])))\n",
    " \n",
    "# plot the roc curve for the model\n",
    "pyplot.plot(fpr, tpr, marker='.', label='XGBClassifier')\n",
    "pyplot.scatter(fpr[ix2], tpr[ix2], s=170,marker='o', color='black', label='Best XGBClassifier g_mean')\n",
    "pyplot.scatter(fpr[ix3], tpr[ix3], s=150,marker='x', color='red'  ,label='Best XGBClassifier Confusion F1')\n",
    "pyplot.scatter(fpr[ix4], tpr[ix4], s=100,marker='v', color='red',  label='Best XGBClassifier Confusion matrix 1')\n",
    "pyplot.scatter(fpr[ix5], tpr[ix5], s=100,marker='v', color='blue', label='Best XGBClassifier Confusion matrix 2')\n",
    "pyplot.scatter(fpr[ix6], tpr[ix6], s=100,marker='v', color='black',label='Best XGBClassifier Confusion matrix 3')\n",
    " \n",
    "# axis labels\n",
    "pyplot.xlabel('False Positive Rate')\n",
    "pyplot.ylabel('True Positive Rate')\n",
    "pyplot.legend(loc='lower left', bbox_to_anchor=(1, 0.5))\n",
    "# show the plot\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7c9988",
   "metadata": {},
   "outputs": [],
   "source": [
    "tnv, fpv, fnv, tpv = 1,4,4,1\n",
    "t0, i = thresholds[ix3] , 0\n",
    "t_step=0.01\n",
    "t_m_old=t0\n",
    "t_p_old=t0\n",
    "left_go  = True \n",
    "right_go = True \n",
    "#All values \n",
    "a = np.c_[yhat,testy]\n",
    "print(confusion_matrix(a[:,1], to_labels(a[:,0], t0 )))\n",
    "tn_0, fp_0, fn_0, tp_0 = confusion_matrix(a[:,1], to_labels(a[:,0], t0 )).ravel()\n",
    "value_0 = ((tn_0*tnv)- (fp_0*fpv) -(fn_0*fnv) +(tp_0*tpv))\n",
    "print('Start Value ',value_0)\n",
    "while(i<90 and (left_go or right_go)):\n",
    "    i+=1\n",
    "    #print('Loop id ',i)\n",
    "    #Cut off for left is t_m, right is t_p\n",
    "    t_m=t_m_old-t_step if  left_go  else t_m_old\n",
    "    t_p=t_p_old+t_step if  right_go else t_p_old\n",
    "\n",
    "    a_f = a[(( a[:,0] < t_m)   | ( a[:,0] > t_p))]\n",
    "    #print(confusion_matrix(a_f[:,1], to_labels(a_f[:,0], t0 )))\n",
    "    #a_old is data of the one iter before, \n",
    "    a_old = a[(( a[:,0] < t_m_old)   | ( a[:,0] > t_p_old ))]\n",
    "    #b is data of moved cut off one step left\n",
    "    b     = a[(( a[:,0] < t_m)       | ( a[:,0] > t_p_old ))]\n",
    "    #c is data of moved cut off one step right\n",
    "    c     = a[(( a[:,0] < t_m_old )  | ( a[:,0] > t_p     ))]\n",
    "    #Calculate values for a,b,c\n",
    "    tn_a, fp_a, fn_a, tp_a = confusion_matrix(a_old[:,1], to_labels(a_old[:,0], (t_m_old+t_p_old)/2 )).ravel()\n",
    "    tn_b, fp_b, fn_b, tp_b = confusion_matrix(b[:,1], to_labels(b[:,0], (t_m+t_p)/2)).ravel()\n",
    "    tn_c, fp_c, fn_c, tp_c = confusion_matrix(c[:,1], to_labels(c[:,0], (t_m+t_p)/2)).ravel()\n",
    "    value_a = ((tn_a*tnv)- (fp_a*fpv) -(fn_a*fnv) +(tp_a*tpv))\n",
    "    value_b = ((tn_b*tnv)- (fp_b*fpv) -(fn_b*fnv) +(tp_b*tpv))\n",
    "    value_c = ((tn_c*tnv)- (fp_c*fpv) -(fn_c*fnv) +(tp_c*tpv))\n",
    "    t_m_old=t_m\n",
    "    t_p_old=t_p\n",
    "    #print(tn_a, fp_a, fn_a, tp_a)\n",
    "    #print(tn_b, fp_b, fn_b, tp_b)\n",
    "    #print(tn_c, fp_c, fn_c, tp_c)\n",
    "    #print(value_a,value_b,value_c)\n",
    "    #Deciding which directions to go\n",
    "    left_go  = True if value_b > value_a else False\n",
    "    right_go = True if value_c > value_a else False\n",
    "    #print('Left  ',left_go )\n",
    "    #print('Right ',right_go)\n",
    "    #print('t_m ',round(t_m,4))\n",
    "    #print('t_p ',round(t_p,4))    \n",
    "    #print('------'*3)\n",
    "print('Finish')\n",
    "t_m=t_m_old if  left_go  else t_m_old+t_step\n",
    "t_p=t_p_old if  right_go else t_p_old-t_step\n",
    "print('t_m ',round(t_m,4))\n",
    "print('t_p ',round(t_p,4))\n",
    "a_f = a[(( a[:,0] < t_m)   | ( a[:,0] > t_p))]\n",
    "print(confusion_matrix(a_f[:,1], to_labels(a_f[:,0], t0 )))\n",
    "tn_f, fp_f, fn_f, tp_f = confusion_matrix(a_f[:,1], to_labels(a_f[:,0], t0 )).ravel()\n",
    "value_f = ((tn_f*tnv)- (fp_f*fpv) -(fn_f*fnv) +(tp_f*tpv))\n",
    "print('Finish Value ',value_f)\n",
    "print('Start  with ',a.shape[0],' item')\n",
    "print('Finish with ',a_f.shape[0],' item')\n",
    "print('Coverage rate ',round((a_f.shape[0]/a.shape[0]),3 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3851704",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('If we predict all data CM will be like that')\n",
    "print(confusion_matrix(a[:,1], to_labels(a[:,0], t0 )))\n",
    "print('We will not predict this data')\n",
    "a_mid = a[(( a[:,0] >  t_m)   & ( a[:,0] < t_p))]\n",
    "print(confusion_matrix(a_mid[:,1], to_labels(a_mid[:,0], t0 )))\n",
    "print('After elimination some of the data confusion matrix will be like that.')\n",
    "print(confusion_matrix(a_f[:,1], to_labels(a_f[:,0], t0 )))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63385c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm1=confusion_matrix(a[:,1], to_labels(a[:,0], t0 )).ravel()\n",
    "cm2=confusion_matrix(a_mid[:,1], to_labels(a_mid[:,0], t0 )).ravel()\n",
    "cm3=confusion_matrix(a_f[:,1], to_labels(a_f[:,0], t0 )).ravel()\n",
    "print('Accuracy of All Data      =',(cm1[0]+cm1[3])/(cm1[0]+cm1[1]+cm1[2]+cm1[3]))\n",
    "print('Accuracy of Not used Data =',(cm2[0]+cm2[3])/(cm2[0]+cm2[1]+cm2[2]+cm2[3]))\n",
    "print('Accuracy of Used Data     =',(cm3[0]+cm3[3])/(cm3[0]+cm3[1]+cm3[2]+cm3[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5672844c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Lets See thresholds percentage on graph\n",
    "\n",
    "#Calculate data for graph\n",
    "#Add prediction as a new column\n",
    "a_per=np.c_[ a, to_labels(a[:,0], t0 )]  \n",
    "\n",
    "#Add success to new column\n",
    "a_per=np.c_[ a_per,np.where(a_per[:,1]==a_per[:,2],1,0)]\n",
    "\n",
    "#Sort array for predictions and get success data\n",
    "temp1=a_per[a_per[:, 0].argsort()][:,3]\n",
    "\n",
    "# np.where(temp[:,0]>t_m,1,0)  gives us a array of 0 and 1 that is lower form t_m values\n",
    "# np.unique gives counts of the uniq values in the array\n",
    "# I divide zero count to orjinal array size and multipliye with 100 and get Percentage for thresholds\n",
    "temp2=a_per[a_per[:, 0].argsort()]\n",
    "t_m_radip = round((np.unique(np.where(temp2[:,0]>t_m,1,0), return_counts=True)[1][0]/len(temp2))*100)\n",
    "t_0_radip = round((np.unique(np.where(temp2[:,0]>t0 ,1,0), return_counts=True)[1][0]/len(temp2))*100)\n",
    "t_p_radip = round((np.unique(np.where(temp2[:,0]>t_p,1,0), return_counts=True)[1][0]/len(temp2))*100)\n",
    "\n",
    "#Define x,y points for the threshols lines\n",
    "x1=[t_m_radip,t_m_radip]\n",
    "x2=[t_0_radip,t_0_radip]\n",
    "x3=[t_p_radip,t_p_radip]\n",
    "\n",
    "# X is percentage and it is range wit  zero to 100, actual 0 to 1\n",
    "x = np.arange(0, 100, 1)\n",
    "# Y is accuracy for the all percentage of the data, \n",
    "# first split cucces column to 100\n",
    "# then sum the chunks and divide to junk size\n",
    "y = [sum(array)/(len(temp1)/100) for array in np.array_split(temp1,  100)]\n",
    "\n",
    "#Define y points as minimum ACC point so graph is not so big\n",
    "y_min=min(y)\n",
    "y1=[y_min,1]\n",
    "y2,y3 = y1,y1\n",
    "\n",
    "#Graph code \n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(x, y)\n",
    "\n",
    "ax.plot(x1, y1, x2, y2,x3, y3,  marker = 'o')\n",
    "\n",
    "\n",
    "ax.set(xlabel='Percentage of Probality', ylabel='Accuracy',\n",
    "       title='Succes of each Persentage of Probality')\n",
    "ax.grid()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
